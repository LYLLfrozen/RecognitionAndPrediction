#!/usr/bin/env python3
"""
æ¨¡å‹è¯Šæ–­è„šæœ¬
æ£€æŸ¥æ¨¡å‹æ˜¯å¦èƒ½æ­£ç¡®è¯†åˆ«å„ç§æ”»å‡»ç±»å‹
"""

import torch
import numpy as np
import pickle
import os
from collections import Counter

from federated_learning.vfl_utils import split_features_for_cnn

# åŠ è½½é…ç½®
device = torch.device("mps" if torch.backends.mps.is_available() else "cpu")
print(f"ä½¿ç”¨è®¾å¤‡: {device}")

# åŠ è½½æ¨¡å‹é…ç½®
with open('models/vfl_network/config.pkl', 'rb') as f:
    config = pickle.load(f)

print(f"\næ¨¡å‹ç±»åˆ«: {config['class_names']}")
print(f"ç±»åˆ«æ•°: {len(config['class_names'])}")

# åŠ è½½æµ‹è¯•æ•°æ®
X_test = np.load('data/processed_data/test_images.npy')
y_test = np.load('data/processed_data/test_labels.npy')

print(f"\næµ‹è¯•é›†å½¢çŠ¶: {X_test.shape}")
print(f"æ ‡ç­¾å½¢çŠ¶: {y_test.shape}")

# æ ‡ç­¾åˆ†å¸ƒ
print(f"\næµ‹è¯•é›†æ ‡ç­¾åˆ†å¸ƒ:")
label_counts = Counter(y_test)
for label, count in sorted(label_counts.items()):
    print(f"  {label} ({config['class_names'][label]:8s}): {count:6d} ({count/len(y_test)*100:.2f}%)")

# åŠ è½½æ¨¡å‹
from federated_learning.vfl_utils import create_vfl_model_split
bottom_models, top_model = create_vfl_model_split(
    config['num_parties'], config['shapes'], num_classes=len(config['class_names'])
)

top_model.load_state_dict(
    torch.load('models/vfl_network/top_model.pth', map_location=device)
)

for i, model in enumerate(bottom_models):
    model.load_state_dict(
        torch.load(f'models/vfl_network/bottom_model_party{i+1}.pth', map_location=device)
    )

top_model.eval()
for model in bottom_models:
    model.eval()

bottom_models = [m.to(device) for m in bottom_models]
top_model = top_model.to(device)

print("\næ¨¡å‹å·²åŠ è½½")

# æµ‹è¯•æ¯ä¸ªç±»åˆ«çš„æ ·æœ¬
print("\n" + "="*80)
print("æµ‹è¯•å„ç±»åˆ«æ ·æœ¬çš„é¢„æµ‹æƒ…å†µ")
print("="*80)

for target_label in range(len(config['class_names'])):
    class_name = config['class_names'][target_label]
    
    # æ‰¾åˆ°è¿™ä¸ªç±»åˆ«çš„æ‰€æœ‰æ ·æœ¬
    indices = np.where(y_test == target_label)[0]
    
    if len(indices) == 0:
        print(f"\n[{class_name}] æ— æµ‹è¯•æ ·æœ¬")
        continue
    
    print(f"\n[{class_name}] å…± {len(indices)} ä¸ªæ ·æœ¬")
    
    # éšæœºé€‰æ‹©æœ€å¤š100ä¸ªæ ·æœ¬è¿›è¡Œæµ‹è¯•
    test_indices = np.random.choice(indices, min(100, len(indices)), replace=False)
    
    predictions = []
    confidences = []
    
    with torch.no_grad():
        for idx in test_indices:
            flow = X_test[idx:idx+1]
            
            # å‚ç›´åˆ†å‰²
            X_parties, _ = split_features_for_cnn(flow, config['num_parties'])
            
            # å„æ–¹è®¡ç®—åµŒå…¥
            embeddings = []
            for i, model in enumerate(bottom_models):
                X_tensor = torch.FloatTensor(X_parties[i]).to(device)
                emb = model(X_tensor)
                embeddings.append(emb)
            
            # èšåˆ
            combined = torch.cat(embeddings, dim=-1)
            
            # é¢„æµ‹
            outputs = top_model(combined)
            probs = torch.softmax(outputs, dim=1)
            confidence, predicted = probs.max(1)
            
            predictions.append(predicted.item())
            confidences.append(confidence.item())
    
    # ç»Ÿè®¡é¢„æµ‹ç»“æœ
    pred_counts = Counter(predictions)
    correct = sum(1 for p in predictions if p == target_label)
    accuracy = correct / len(predictions) * 100
    
    print(f"  å‡†ç¡®ç‡: {accuracy:.2f}% ({correct}/{len(predictions)})")
    print(f"  å¹³å‡ç½®ä¿¡åº¦: {np.mean(confidences):.4f}")
    print(f"  é¢„æµ‹åˆ†å¸ƒ:")
    for pred_label, count in sorted(pred_counts.items()):
        pred_name = config['class_names'][pred_label]
        marker = "âœ“" if pred_label == target_label else "âœ—"
        print(f"    {marker} {pred_name:8s}: {count:3d} ({count/len(predictions)*100:.1f}%)")

print("\n" + "="*80)
print("è¯Šæ–­å®Œæˆ")
print("="*80)

# æ€»ç»“é—®é¢˜
print("\nğŸ” é—®é¢˜åˆ†æ:")
print("  å¦‚æœDOSã€R2Lç­‰æ”»å‡»ç±»å‹çš„å‡†ç¡®ç‡å¾ˆä½ï¼Œå¯èƒ½åŸå› :")
print("  1. æ•°æ®ä¸å¹³è¡¡ - æŸäº›ç±»åˆ«æ ·æœ¬å¤ªå°‘ï¼ˆå¦‚R2Låªæœ‰225ä¸ªï¼ŒU2Råªæœ‰10ä¸ªï¼‰")
print("  2. æ¨¡å‹è¿‡æ‹Ÿåˆåˆ°å¤šæ•°ç±»ï¼ˆnormalå’Œdoså 98%ï¼‰")
print("  3. ç‰¹å¾æå–ä¸å……åˆ† - çœŸå®æµé‡ç‰¹å¾å’Œè®­ç»ƒæ•°æ®æ ¼å¼ä¸åŒ¹é…")
print("  4. æ¨¡å‹è®­ç»ƒä¸å……åˆ† - éœ€è¦æ›´å¤šè®­ç»ƒè½®æ¬¡æˆ–è°ƒæ•´æŸå¤±å‡½æ•°")
